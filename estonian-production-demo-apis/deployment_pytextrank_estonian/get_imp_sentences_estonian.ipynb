{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"\"\"Kui emme tahab kinno, siis emme läheb kinno!\n",
    "Võta beebi kaasa, sõbrannad ligi ja Solaris Kino ootab teid!\n",
    "NB! Emme ja Beebi Kinopäevale on ka issid väga teretulnud!\n",
    "Imelises Kehrwiederi Jäätisekohvikus kinopileti esitamisel saavad emmed ja nende beedid 2 teed või 2 mahla ühe hinnaga, samuti pakutakse 10% soodustust teistele jookidele ja kookidele.\n",
    "Kohvikus Komeet ootab teid spetsiaalne BEEBIMENÜÜ – klientidele vanuses 1-17 kuud. Valmistame erinevaid värskeid aed- ja puuviljamehusid ning püreesid kõige pisematele.\n",
    "Lase oma sisemine sportlane välja. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sent_tokenize(story)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten list\n",
    "sentences = [y for x in sentences for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kui emme tahab kinno, siis emme läheb kinno!',\n",
       " 'Võta beebi kaasa, sõbrannad ligi ja Solaris Kino ootab teid!',\n",
       " 'NB!',\n",
       " 'Emme ja Beebi Kinopäevale on ka issid väga teretulnud!',\n",
       " 'Imelises Kehrwiederi Jäätisekohvikus kinopileti esitamisel saavad emmed ja nende beedid 2 teed või 2 mahla ühe hinnaga, samuti pakutakse 10% soodustust teistele jookidele ja kookidele.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuations, numbers and special characters \n",
    "clean_sentences = pd.Series(sentences).str.replace(\"[.!?\\\\-]\", \" \") \n",
    "clean_sentences = pd.Series(clean_sentences).str.replace(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \")\n",
    "# make alphabets lowercase \n",
    "clean_sentences = [s.lower() for s in clean_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kui emme tahab kinno, siis emme läheb kinno ',\n",
       " 'võta beebi kaasa, sõbrannad ligi ja solaris kino ootab teid ',\n",
       " 'nb ',\n",
       " 'emme ja beebi kinopäevale on ka issid väga teretulnud ',\n",
       " 'imelises kehrwiederi jäätisekohvikus kinopileti esitamisel saavad emmed ja nende beedid teed või mahla ühe hinnaga, samuti pakutakse 10% soodustust teistele jookidele ja kookidele ']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mul', 'sa', 'kui', 'oled', 'mida', 'aga', 'mu', 'siis', 'ära', 'nad', 'siin', 'mulle', 'ta', 'seda', 'see', 'oma', 'et', 'on', 'selle', 'mis', 'olen', 'pole', 'jah', 'ei', 'kõik', 'mind', 'me', 'minu', 'ma', 'oli', 'nii', 'kas', 'ja', 'te', 'midagi'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stop_words = set(line.strip() for line in open('stopwords-et.txt'))\n",
    "print (stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove stopwords \n",
    "def remove_stopwords(sen):     \n",
    "    sen_new = \" \".join([i for i in sen if i not in stop_words])          \n",
    "    return sen_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emme tahab kinno, emme läheb kinno', 'võta beebi kaasa, sõbrannad ligi solaris kino ootab teid', 'nb', 'emme beebi kinopäevale ka issid väga teretulnud', 'imelises kehrwiederi jäätisekohvikus kinopileti esitamisel saavad emmed nende beedid 2 teed või 2 mahla ühe hinnaga, samuti pakutakse 10% soodustust teistele jookidele kookidele', 'kohvikus komeet ootab teid spetsiaalne beebimenüü – klientidele vanuses 1 17 kuud', 'valmistame erinevaid värskeid aed puuviljamehusid ning püreesid kõige pisematele', 'lase sisemine sportlane välja']\n"
     ]
    }
   ],
   "source": [
    "# remove stopwords from the sentences \n",
    "clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]\n",
    "print (clean_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329987 300\n",
      "\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n"
     ]
    }
   ],
   "source": [
    "# Extract word vectors \n",
    "word_embeddings = {} \n",
    "# f = open('wiki.et.vec', encoding='utf-8') \n",
    "# firstLine = f.pop(0)\n",
    "dimension = 0\n",
    "with open('wiki.et.vec', encoding='utf-8') as f:\n",
    "    first_line = f.readline()\n",
    "    dimension = int(first_line.split()[-1])\n",
    "    print (first_line)\n",
    "    for line in f: \n",
    "        values = line.split() \n",
    "        word = values[0]\n",
    "        #print (word)\n",
    "        try:\n",
    "            coefs = np.asarray(values[1:], dtype='float32') \n",
    "            assert(len(values[1:])==300)\n",
    "            word_embeddings[word] = coefs\n",
    "        except:\n",
    "            print (\"error\")\n",
    "        \n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329900\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print (len(list(word_embeddings.keys())))\n",
    "print (dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectors = [] \n",
    "for i in clean_sentences: \n",
    "  if len(i) != 0: \n",
    "    v = sum([word_embeddings.get(w, np.zeros((dimension,))) for w in  \n",
    "        i.split()])/(len(i.split())+0.001) \n",
    "  else: \n",
    "    v = np.zeros((dimension,)) \n",
    "  sentence_vectors.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity matrix \n",
    "sim_mat = np.zeros([len(sentences), len(sentences)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)): \n",
    "  for j in range(len(sentences)): \n",
    "    if i != j: \n",
    "      sim_mat[i][j] = cosine_similarity (sentence_vectors[i].reshape(1,dimension), sentence_vectors[j].reshape(1,dimension))[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "nx_graph = nx.from_numpy_array(sim_mat) \n",
    "scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Võta beebi kaasa, sõbrannad ligi ja Solaris Kino ootab teid!\n",
      "Emme ja Beebi Kinopäevale on ka issid väga teretulnud!\n",
      "Kohvikus Komeet ootab teid spetsiaalne BEEBIMENÜÜ – klientidele vanuses 1-17 kuud.\n"
     ]
    }
   ],
   "source": [
    "ranked_sentences = sorted(((scores[i],s) for i,s in \n",
    "                           enumerate(sentences)), reverse=True)\n",
    "\n",
    "n_sentences = int(np.ceil(len(ranked_sentences) ** 0.5))\n",
    "# Extract top 10 sentences as the summary \n",
    "for i in range(n_sentences): \n",
    "  print(ranked_sentences[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
